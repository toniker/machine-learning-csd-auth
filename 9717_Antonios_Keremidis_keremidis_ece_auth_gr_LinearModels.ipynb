{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeF4qTmfveeb"
   },
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE` (replacing the dots). After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this assignment in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel>Restart) and then **run all cells** (in the menubar, select Cell>Run All). \n",
    "\n",
    " **What you need to remember:**\n",
    "\n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
    "- Write code in the designated areas using Python 3 only\n",
    "- Do not modify the code outside of the designated areas\n",
    "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
    "\n",
    "Fill in your **NAME** and **AEM** below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "ZCY3tJjnveei"
   },
   "outputs": [],
   "source": [
    "NAME = \"Antonios Keremidis\"\n",
    "AEM = \"9717\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpED3Vwlveek"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0LK7HlL9r2k1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ccc99a100da955945679879e451af2f7",
     "grade": false,
     "grade_id": "cell-62cb5c0bfe7b0be0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 1 - Linear Models #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ww0lVWmTsBOF",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95ccc5bf6599c4fefd13589ec56ecf36",
     "grade": false,
     "grade_id": "cell-61376cfdc59ad4b7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Welcome to your first assignment. This exercise gives you a brief introduction to Python and the fundamental libraries for machine learning. It also gives you a wide understanding on how linear models work.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "gK7GYZ6ouIGC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b163a472e31417e98fd907a65646e15",
     "grade": false,
     "grade_id": "cell-e2c88db06666ef54",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "After this assignment you will:\n",
    "- Be able to use iPython Notebooks\n",
    "- Be able to use numpy and pandas functions\n",
    "- Be able to build your first linear model from scratch\n",
    "- Be able to use the basic functions of scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lQix4mv62BT4",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "562b7c489c155b2a7b8abe0d6412d099",
     "grade": false,
     "grade_id": "cell-e62e23002ad81abc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Exercise**: Set test to `\"Hello World\"` in the cell below to print \"Hello World\" and run the two cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "deletable": false,
    "id": "smvHiyLY15i6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc2ac46cb8d87335566db4fb6df6e16a",
     "grade": false,
     "grade_id": "cell-e3618902cab063ed",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "test = \"Hello World\"\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "Y-_OySPk1_oh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ab6d88aef434b5543877c0b49174a77",
     "grade": true,
     "grade_id": "cell-0761ffa58244965c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "71f0947c-dd08-41b8-e22d-26cf726f5894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Hello World\n"
     ]
    }
   ],
   "source": [
    "print (\"test: \" + test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Tn9L2Oq82PPC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b7ed43fbf47beb8715d1fa70bb33594",
     "grade": false,
     "grade_id": "cell-2523086cd6ee1f4b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Expected output**:\n",
    "\n",
    "test: Hello World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lzpRolujz4zs",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e46c1d92818113136db5ec1fb85219d",
     "grade": false,
     "grade_id": "cell-36315b2ebbf1eecb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 1. Numpy & Pandas ##\n",
    "\n",
    "The [**NumPy**](https://numpy.org/) library is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays. \n",
    "\n",
    "The [**Pandas**](https://pandas.pydata.org/) library is built on NumPy and provides easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "Feel free to look at the documentation ([NumPy Doc](https://numpy.org/doc/1.18/user/quickstart.html) & [Pandas Doc](https://pandas.pydata.org/docs/)) of those libraries troughout this assignment. \n",
    "\n",
    "As a convention we always import the libraries as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "ydtbUhRK1Mwd"
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "R047IOKS0jbm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "304a9d8a950eeccee8131d7bb8096ca6",
     "grade": false,
     "grade_id": "cell-72e9db57f4d96a10",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.1 The very basic of NumPy ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dDa8wbkp3tcJ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90c22b9e300426e6cb093bb63ea2efb0",
     "grade": false,
     "grade_id": "cell-3c71a9b8c65496dc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.1.1 Exercise**: Create a 3-dimensional *NumPy* array (3x3) which contains the numbers 1-9 on variable 'a'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "deletable": false,
    "id": "sRd0XYXap0KQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e508824af6ad4bc1c3b85153190a6af",
     "grade": false,
     "grade_id": "cell-fbaa0138d806f312",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "a = np.arange(9).reshape(3, 3)\n",
    "a = a + 1\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "CVI97RDG5NrY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a713e39ed56c0da7b2fa6ed10bcd92fb",
     "grade": true,
     "grade_id": "cell-17d73239f39ff6cc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "d5720ded-7dae-401e-d95f-01ab2b51e415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "58zW8z295bSK",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fdd0160389167cff660e0485be6ca18f",
     "grade": false,
     "grade_id": "cell-0194f8098f7d5d17",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Expected output:** \n",
    "\n",
    "\n",
    "```\n",
    "[[1 2 3]\n",
    " [4 5 6]\n",
    " [7 8 9]]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eEsIzDKU63UA",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c44c8b7d97443d43f4903ab0909a06c9",
     "grade": false,
     "grade_id": "cell-699269795ce87979",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.1.2 Exercise**: Assign the 2nd element of the 2nd row of variable **a** to variable **el**. Moreover, assign the first 2 elements of the 2nd column of array **a** to variable **col**. *Tip: Use slicing* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "deletable": false,
    "id": "Z99j4XAs5Xwu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32959e6aea2b9c289567d8f459b6a214",
     "grade": false,
     "grade_id": "cell-8a8a1d5b54c1a5b2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "el = a[1, 1]\n",
    "col = a[0:2, 1]\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "J91SRxNt7kQR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c64b56a85aad0db5de3b3d2e66c9ae7b",
     "grade": true,
     "grade_id": "cell-7a94780517e024bf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "cb856371-0a50-4360-bb3b-351f7df523d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el:5\n",
      "col:[2 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"el:\" + str(el))\n",
    "print(\"col:\" + str(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "-VzK9qi38H1q",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb71fbeeb49410b1b20e2e72155f8958",
     "grade": false,
     "grade_id": "cell-cdfee79e1561651a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Expected output:** \n",
    "<table>\n",
    "    <tr> \n",
    "        <td> el: </td> \n",
    "        <td> 5 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td> col: </td> \n",
    "    <td> [2,5] </td>\n",
    "    </tr>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "iik38C3V9IFK",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43f59c26f06c7a74420e74bdb6c6a0a5",
     "grade": false,
     "grade_id": "cell-1a3520a0d3f88ee6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.1.3 Exercise**: Create a 3x4 array full of zeros, create an 2x3 array full of ones and 4x5 array full of random values (0 to 10) using the fucntions np.zeros, np.ones, and np.random.random accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "deletable": false,
    "id": "dcXkLapD7nce",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7cfe64178ada9a5ebff4bb28ffe3ee81",
     "grade": false,
     "grade_id": "cell-12a2471cada03991",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# BEGIN CODE HERE\n",
    "zero_array =  np.zeros([3,4])\n",
    "one_array = np.ones([2,3])\n",
    "random_array = np.random.random([4,5])\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "JIU2YWX18E5b",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff7492f8bd8643cc3dff1e828e965ca5",
     "grade": true,
     "grade_id": "cell-2fa3e8e2357fcf87",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "75a884bd-23fe-4227-c9db-38c8de357c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_array: [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "one_array: [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "random_array: [[0.37454012 0.95071431 0.73199394 0.59865848 0.15601864]\n",
      " [0.15599452 0.05808361 0.86617615 0.60111501 0.70807258]\n",
      " [0.02058449 0.96990985 0.83244264 0.21233911 0.18182497]\n",
      " [0.18340451 0.30424224 0.52475643 0.43194502 0.29122914]]\n"
     ]
    }
   ],
   "source": [
    "print(\"zero_array:\", zero_array)\n",
    "print(\"one_array:\", one_array)\n",
    "print(\"random_array:\", random_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHxxqefExwKA"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "zero_array: [[0. 0. 0. 0.]\n",
    " [0. 0. 0. 0.]\n",
    " [0. 0. 0. 0.]]\n",
    "\n",
    "one_array: [[1. 1. 1.]\n",
    " [1. 1. 1.]]\n",
    "\n",
    "random_array: [[0.37454012 0.95071431 0.73199394 0.59865848 0.15601864]\n",
    " [0.15599452 0.05808361 0.86617615 0.60111501 0.70807258]\n",
    " [0.02058449 0.96990985 0.83244264 0.21233911 0.18182497]\n",
    " [0.18340451 0.30424224 0.52475643 0.43194502 0.29122914]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tySai5aIFVJC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6a9d4bbfed398d52187df7fcf1909b6",
     "grade": false,
     "grade_id": "cell-b207f4139851372d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Two common numpy functions used are [np.shape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html) and [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html). \n",
    "- X.shape is used to get the shape (dimension) of a matrix/vector X. \n",
    "- X.reshape(...) is used to reshape X into some other dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlzbLWeEyvo7"
   },
   "source": [
    "**1.1.4 Exercise**: Use the function **shape** to print the shape of variable **random_array** and the function **reshape** to change the dimensions of **one_array** from 2x3 to 1x6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "5QJUgXPIzN6Z"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# BEGIN CODE HERE\n",
    "shape_random_array = np.shape(random_array)\n",
    "reshaped_one_array = one_array.reshape(1, -1)\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGrHh-YdzQBb",
    "outputId": "00e46523-6439-43cb-db9a-694fa2094403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_random_array: (4, 5)\n",
      "reshaped_one_array: [[1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"shape_random_array:\", shape_random_array)\n",
    "print(\"reshaped_one_array:\", reshaped_one_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75XEG3KHzpGh"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "shape_random_array: (4, 5)\n",
    "reshaped_one_array: [[1. 1. 1. 1. 1. 1.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vZhJzYRGF9zG",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47d2e59150fee69d309b6cf52359ea99",
     "grade": false,
     "grade_id": "cell-af88a87eac6bd364",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.1.5 Exercise**: Implement the function **custom_reshape** that takes as input an array of shape (length, height, depth) and returns a vector of shape (length\\*height\\*depth, 1). \n",
    "\n",
    "(Tips: you can use .shape to find length, height, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "deletable": false,
    "id": "pkZYNHUd-lHI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1407cc96ca0642fe73c47336bb221a66",
     "grade": false,
     "grade_id": "cell-5ba0e15615d720a6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def custom_reshape(my_array):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    my_array -- a numpy array of shape (length, height, depth)\n",
    "    \n",
    "    Returns:\n",
    "    v -- a vector of shape (length*height*depth, 1)\n",
    "    \"\"\"\n",
    "    # BEGIN CODE HERE\n",
    "    v = my_array.reshape(-1, 1)\n",
    "    #END CODE HERE\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "GXm1d3xpG8tC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d249705ca464fc7f97a3abacc9ce833",
     "grade": true,
     "grade_id": "cell-270444659016ab2f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "b6cb3a5e-3e18-4b0e-8558-1dab1a77edc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_reshape(my_array) = [[0.67826139]\n",
      " [0.29380381]\n",
      " [0.4215251 ]\n",
      " [0.45017551]\n",
      " [0.92814219]\n",
      " [0.96677647]\n",
      " [0.19981397]\n",
      " [0.27417313]\n",
      " [0.60659855]\n",
      " [0.00533165]\n",
      " [0.34144279]\n",
      " [0.94630077]]\n"
     ]
    }
   ],
   "source": [
    "# This is a 3 by 2 by 2 array.\n",
    "my_array = np.array([[[ 0.67826139,  0.29380381],\n",
    "                      [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "                      [[ 0.92814219,  0.96677647],\n",
    "                        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "                      [[ 0.60659855,  0.00533165],\n",
    "                        [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "print (\"custom_reshape(my_array) = \" + str(custom_reshape(my_array)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fEzC25g3HSl_",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9aeb5071814954d38141ef7221a5d9d6",
     "grade": false,
     "grade_id": "cell-db1ff76b8d993506",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Expected Output**: \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "custon_reshape(my_array) = [[0.67826139]\n",
    " [0.29380381]\n",
    " [0.4215251 ]\n",
    " [0.45017551]\n",
    " [0.92814219]\n",
    " [0.96677647]\n",
    " [0.19981397]\n",
    " [0.27417313]\n",
    " [0.60659855]\n",
    " [0.00533165]\n",
    " [0.34144279]\n",
    " [0.94630077]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "o3DYNNXZIbYd",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69a8da5cff899b8dd1fa6b5e8e931a14",
     "grade": false,
     "grade_id": "cell-cea361d2c51faef2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.1.6 Exercise**: Create an array of 9 evenly spaced values from 0 to 3 using the np.linspace() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false,
    "id": "YLm1wTnwHHaP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f5e403f465cd031fb594c881134caad",
     "grade": false,
     "grade_id": "cell-8b54354fe40e9e69",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "x = np.linspace(0, 3, 9, True, False)\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "rz_J06kzKqsa",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5cad77ff7c81287529ca2ca7f48dd67",
     "grade": true,
     "grade_id": "cell-c7fa43b349200975",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "e01788a7-5f45-472e-ddee-93a6cf2bae11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.    0.375 0.75  1.125 1.5   1.875 2.25  2.625 3.   ]\n"
     ]
    }
   ],
   "source": [
    "print (\"x: \" + str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmIfxCjV1RnF"
   },
   "source": [
    "**Expected outcome:**\n",
    "\n",
    "```\n",
    "x: [0.    0.375 0.75  1.125 1.5   1.875 2.25  2.625 3.   ]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "P-wd0gUgO_ud",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d49a30f348a6f5065f4092d266e36190",
     "grade": false,
     "grade_id": "cell-ea2656904d795b46",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.1.7 Exercise**: Draw 5 random samples from a multivariate normal distribution using the [np.random.multivariate_normal](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.multivariate_normal.html#numpy.random.multivariate_normal). (Tip: Use the parameters given as arguments. Check documentation for the correct order of arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "deletable": false,
    "id": "JrbNyLGIKxlg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef6bc67133b9fcea36942434d55c3dc9",
     "grade": false,
     "grade_id": "cell-2a9c3ba6c99bd3e8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "num_observations = 5\n",
    "mean = [0, 0]\n",
    "cov = [[1, 0], [0, 100]]\n",
    "\n",
    "# BEGIN CODE HERE\n",
    "multi = np.random.multivariate_normal(mean, cov, num_observations)\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "HpfTZJydGWYy",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c210de64e5d920cbc63f27d15b3531f",
     "grade": true,
     "grade_id": "cell-619e6322c1ac5741",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "0a716581-8dfb-43af-b4e8-804d3204c17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[-0.1382643   4.96714153]\n",
      " [ 1.52302986  6.47688538]\n",
      " [-0.23413696 -2.34153375]\n",
      " [ 0.76743473 15.79212816]\n",
      " [ 0.54256004 -4.69474386]]\n"
     ]
    }
   ],
   "source": [
    "print (\"x: \" + str(multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97DUZ6iB15A4"
   },
   "source": [
    "**Expected outcome:**\n",
    "\n",
    "```\n",
    "x: [[-0.1382643   4.96714153]\n",
    " [ 1.52302986  6.47688538]\n",
    " [-0.23413696 -2.34153375]\n",
    " [ 0.76743473 15.79212816]\n",
    " [ 0.54256004 -4.69474386]]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QUoFxsrhHcTC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7edb1f59507663051751bfaab105ad15",
     "grade": false,
     "grade_id": "cell-6eaf28f729f9e542",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.1.8 Exercise**: Change the **...** so the scatter plot shows the values of the *multi* variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "deletable": false,
    "id": "0IOzhD78QTwe",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d47a0379d7a2b7094d1870534258a12b",
     "grade": true,
     "grade_id": "cell-c3451c6fcbd04065",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x164bd5060>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 360x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this block to see a visual represntation of your samples.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,5))\n",
    "# BEGIN CODE HERE\n",
    "plt.scatter(multi[0:num_observations, 0],\n",
    "            multi[0:num_observations, 1],\n",
    "            c = 'r', alpha = .4)\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRhZvHsYvFjV"
   },
   "source": [
    "**1.1.9 Exercise**: Create a dictionary (hashmap) containing two keys: *data*, *shape* and assign them the variables **multi**, and the shape of variable **multi**, respectively. Then, you should retrieve the values of both keys and assign the first row of the value of *data* key to the variable **first_row_of_multi**, and assign the value of *shape* key to the variable **shape_of_multi**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "KEjffLTyv0IO"
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "hashmap = dict({ \"data\" :multi,\n",
    "                 \"shape\" : multi.shape})\n",
    "first_row_of_multi = hashmap.get(\"data\")[0]\n",
    "shape_of_multi = hashmap.get(\"shape\")\n",
    "#END CODE HERE\n",
    "assert (isinstance(hashmap, dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "ohCOKmzzwtv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row of variable multi: [-0.1382643   4.96714153]\n",
      "Shape of variable multi:     (5, 2)\n"
     ]
    }
   ],
   "source": [
    "print('First row of variable multi:', first_row_of_multi)\n",
    "print('Shape of variable multi:    ', shape_of_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1dGspykyLUD"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "First row of variable multi: [-0.1382643   4.96714153]\n",
    "Shape of variable multi:     (5, 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "V--bLaLSRE2y",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad41b2945662342c1395087603adfc47",
     "grade": false,
     "grade_id": "cell-7c380b97c5fc06a2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.2 The very basics of Pandas ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xIHQMFo_RisD",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "331ae06f92bb962955a2dda47cf6d015",
     "grade": false,
     "grade_id": "cell-b5ae015fc71a9d22",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "- Read & Write CSV\n",
    "- iloc, loc, and slices\n",
    "- Merge & concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_41lZvsfCqAp",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4356220fa477bd021de8d2235e3eeb4",
     "grade": false,
     "grade_id": "cell-35f23625c6db91ad",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.2.1 Exercise:** Read the file input1.csv into a dataframe using the pandas read_csv() function. Set the 1st row as the names of the columns (Tip: use the *header* argument)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "deletable": false,
    "id": "6-pHq6FcEw8_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c728559431b695e78382485700a2b48",
     "grade": true,
     "grade_id": "cell-7393b2df6214689f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [121]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# BEGIN CODE HERE\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df1 \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput1.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sandbox/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sandbox/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    666\u001B[0m     dialect,\n\u001B[1;32m    667\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    677\u001B[0m )\n\u001B[1;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sandbox/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sandbox/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sandbox/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[1;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[0;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[1;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sandbox/lib/python3.10/site-packages/pandas/io/common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'input1.csv'"
     ]
    }
   ],
   "source": [
    "# BEGIN CODE HERE\n",
    "df1 = pd.read_csv('input1.csv', header=0)\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CP-TMTEJGJFy",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee9c56b977370278eb59c7e3f5dcc734",
     "grade": false,
     "grade_id": "cell-874ff1d909b5aa3c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9XWwZLTRIarc",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "336a187189c7f479e4f944734749377a",
     "grade": false,
     "grade_id": "cell-c4918726834a571d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.2.2 Exercise:** Find the mean value of the *chol* variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "wG2O0oTZIrFR",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bf12680f5840793cf5aaadd6f908a4a",
     "grade": false,
     "grade_id": "cell-c9ffcf3a751e1f97",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "mean_chol = df1[\"chol\"].mean(axis=0)\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Oc3WyE2PI0z-",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8e6143286a86f156fa4dffc466a4e24",
     "grade": true,
     "grade_id": "cell-898f605e5d549af1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Average: \" + str(mean_chol) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcUwmk9x4Muf"
   },
   "source": [
    "**Expected outcome:**\n",
    "\n",
    "```\n",
    "Average: 248.13\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GhvZ-oYSK3gg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed351122807f3b8a05fd80279e60c05b",
     "grade": false,
     "grade_id": "cell-f1a84ce76c579715",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.2.3 Exercise:** Read the file input2.csv into a dataframe using the pandas read_csv() function and concatenate it with df1 using pd.concat(). (Note: input2.csv has no **header**! Note 2: You should use the columns of **df1** in **df2**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "JH4eXERVLCei",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad9691aceaad0d451ed6c8de2719e469",
     "grade": true,
     "grade_id": "cell-2557b9275a04ae8b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "df2 = pd.read_csv('input2.csv')\n",
    "df2.columns = df1.columns\n",
    "df = pd.concat([df1 ,df2])\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9AtvDaijLUdM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa94d9091fc7a03edae6c525c697a015",
     "grade": false,
     "grade_id": "cell-559a3277fa81ffdc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9QK8m9GRMNl4",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0ff945d9969c0f8e85bfad047335b8e",
     "grade": false,
     "grade_id": "cell-320230170fd85580",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**1.2.4 Exercise:** Select the rows where *chol*>400 and only the columns age, sex, cp, chol, target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "2JPOulxuMhJL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a990e3ac009f667d936190ad9c173262",
     "grade": true,
     "grade_id": "cell-6cc840a5339e424a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "selected = df[df['chol'] > 400].filter(items=['age', 'sex', 'cp', 'chol', 'target'])\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2afysp0zNI8H",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a373c40e8500c6724c483511ef8d145a",
     "grade": false,
     "grade_id": "cell-48693c5bbb61e79b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d_8E3vdsSe_h",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07c2f55dbfb129d7f518a1e65cf158d2",
     "grade": false,
     "grade_id": "cell-ec91fa8f3d207a07",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 2.0 Linear Models ##\n",
    "\n",
    "In this part of the excersice you are going to build a logistic regression model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sJMbzOu6QGqL",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "500e359861de99caea19bbc01977a10c",
     "grade": false,
     "grade_id": "cell-5dbf93d86dbdf181",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**2.1 Exercise:** Implement the sigmoid function using numpy. \n",
    "\n",
    "sigmoid function:\n",
    "$$\\sigma(t)= \\dfrac{1}{1 + exp(-t)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "FDBfIMSNQYmZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d979d15e4854581735443b06fa9790ba",
     "grade": false,
     "grade_id": "cell-fb0446f35e18e729",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(t):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of t\n",
    "    Arguments:\n",
    "    t -- A numpy array of any size\n",
    "    Return:\n",
    "    s -- sigmoid(t)\n",
    "    \"\"\"\n",
    "    # BEGIN CODE HERE\n",
    "    s = 1 / (1 + np.exp(-1 * t))\n",
    "    #END CODE HERE\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZRqupxwKRcRp",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98c34231b27c1d8be90deee50f23dc18",
     "grade": true,
     "grade_id": "cell-e7b2acaec5f0218a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([2, 3, 4])\n",
    "print(sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGoj1Q4I7z9B"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "[0.88079708 0.95257413 0.98201379]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KFYp1zjbRt9p",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4307fe509f7462d71b458340007a333",
     "grade": false,
     "grade_id": "cell-b79127fca8834e46",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**2.2 Exercise**: Implement parameter initialization in the cell below. You have to initialize w (weight vector) and b (bias) with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "PiLjAYCnUPSd",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50049aaaa3331bf4b8fa0a0e35652493",
     "grade": false,
     "grade_id": "cell-1f0ef74ec507ba62",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def initialize(dim):\n",
    "    \"\"\"  \n",
    "    Argument:\n",
    "    dim -- the number of parameters\n",
    "\n",
    "    Returns:\n",
    "    w -- initialized vector of shape (1, dim)\n",
    "    b -- initialized bias weight\n",
    "    \"\"\"\n",
    "    # BEGIN CODE HERE\n",
    "    w = np.zeros((dim,))\n",
    "    b = 0\n",
    "    #END CODE HERE\n",
    "\n",
    "    assert(w.shape == (dim,))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "50YvP0ABYj8z",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cac7c75ae3ba755f737c9a2e31e9225",
     "grade": true,
     "grade_id": "cell-15e1a42f5173d30b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dim = 5\n",
    "w, b = initialize(dim)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VS7zKY8487hB"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "\n",
    "```\n",
    "w = [0. 0. 0. 0. 0.]\n",
    "b = 0\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "aUOVogDFZZ3f",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a844bcdbaac95f0f867fe5eb3e0a1eaa",
     "grade": false,
     "grade_id": "cell-15b03530bea75821",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**2.3 Exercise**: Compute the cost of logistic regression using the sigmoid function above. You can find the dot product of two arrays by using the [np.dot()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html). Check slide 39 (41). (Tip 1: you should append b (weight of bias) in front of w array, Tip 2: Pay attention to 'ML Course - Linear Models' covered in class to see how to combine $x_0$ with the other variables of $X$. Tip 3: You may use np.array, np.c_, np.dot, np.log, np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "pX9ZRpaFVEPF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5add774cd28b1cd1b7f8ca114a86579",
     "grade": false,
     "grade_id": "cell-881ad9c45016bf18",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_cost(w,b,X,Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    w -- weights\n",
    "    b -- bias\n",
    "    X -- input data\n",
    "    Y -- target or label vector\n",
    "\n",
    "    Return:\n",
    "    sigma -- the sigmoid of the z\n",
    "    cost -- cost for logistic regression\n",
    "    \"\"\"\n",
    "    # BEGIN CODE HERE\n",
    "    bw = ... #(Optional)\n",
    "    X = np.insert(X, 0, 1, axis=1) #(Optional)\n",
    "    sigma = sigmoid(np.dot(X ,np.append(b,w)))\n",
    "    cost = (-1 / len(X)) * np.sum(Y * np.log(sigma) + (1 - Y) * np.log(1 - sigma))\n",
    "    #END CODE HERE\n",
    "\n",
    "    return sigma, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "scWsodDMbVen",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77a94642fd333ee19c1cbdfff27720db",
     "grade": true,
     "grade_id": "cell-9d38419c3ebd0acc",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "w, b, X, Y = np.array([1.,2.]), 2., np.array([[1.,3.],[2.,4.],[-1.,-3.2]]), np.array([1,0,1])\n",
    "sigma, cost = compute_cost(w, b, X, Y)\n",
    "print(\"Sigmoid:\",[i for i in sigma])\n",
    "print(\"Cost:\", str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pe43vxVhb8L1",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ceceeab4a917c2e76a6d9aa40fe52625",
     "grade": false,
     "grade_id": "cell-6e9022bd13951d73",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Expected output**:\n",
    "\n",
    "```\n",
    "Sigmoid: [0.9998766054240137, 0.9999938558253978, 0.004496273160941178]\n",
    "Cost: 5.801545319394553\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j15xZTmQdX1e",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4645f9b41fd8bd1541f9d18ee26d514",
     "grade": false,
     "grade_id": "cell-11775dbf025eb93d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**2.4 Exercise** Compute the gradient of w and b. Compute grad as in slide 40 (Compute X and bw like above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "wnf2bruQdfVp",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4e88ce7b3c54d91b2245a5fb58be553",
     "grade": false,
     "grade_id": "cell-b76e1fe6a6515ea3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gradient(w,b,X,Y,sigma):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    w -- weights\n",
    "    b -- bias\n",
    "    X -- input data\n",
    "    Y -- target or label vector\n",
    "\n",
    "    Return:\n",
    "    dw -- gradient of the loss with respect to w (numpy array) \n",
    "    db -- gradient of the loss with respect to b (scalar)\n",
    "    \"\"\"\n",
    "    # BEGIN CODE HERE\n",
    "    bw = np.append(b, w)\n",
    "    X = np.insert(X, 0, 1, axis=1)\n",
    "    grad = (1 / len(X)) * np.dot(X.T, sigma - Y)  #(Optional)\n",
    "    dw = grad[1:]\n",
    "    db = grad[0]\n",
    "\n",
    "    #END CODE HERE\n",
    "\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PsqriY0EeXfz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "994826e70eb04b6e6dee37c95ac0d21b",
     "grade": true,
     "grade_id": "cell-c11254300ee020b3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "w, b, X, Y = np.array([1.,2.]), 2., np.array([[1.,3.],[2.,4.],[-1.,-3.2]]), np.array([1,0,1])\n",
    "dw, db = gradient(w, b, X, Y,sigma)\n",
    "print (\"dw = \" + str(dw))\n",
    "print (\"db = \" + str(db))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "82sKa2BHe3pE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8257c34c378e78b316fc953203accad5",
     "grade": false,
     "grade_id": "cell-e3749a16a1cf0dfc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Expected Output**:\n",
    "\n",
    "\n",
    "```\n",
    "dw = [0.99845601 2.39507239]\n",
    "db = 0.001455578136784208\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kFEC6UNrpFie",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "350a080a31e3e7bef3110bb848618858",
     "grade": false,
     "grade_id": "cell-a89314f33d6ef4cf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**2.5 Exercise** Implement the parameters update function below. The goal is to learn $w$ and $b$ by minimizing the cost function $J$. For a parameter $\\theta$, the update rule is $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, where $\\alpha$ is the learning rate. Tip: Use the functions developed above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Vprh1oA_ps2E",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59c10891c7341bf8f79a9abec6bd50a6",
     "grade": false,
     "grade_id": "cell-050c33f712ee5e19",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def update_parameters(w,b,X,Y,num_iterations,learning_rate):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "\n",
    "      Arguments:\n",
    "      w -- weights\n",
    "      b -- bias\n",
    "      X -- input data\n",
    "      Y -- target or label vector\n",
    "      num_iterations -- number of iterations of the optimization loop\n",
    "      learning_rate -- learning rate of the gradient descent update rule\n",
    "\n",
    "      Returns:\n",
    "      params -- dictionary containing the weights w and bias b\n",
    "      grads -- dictionary containing the gradients of the weights and bias with respect to the cost function.\n",
    "    \"\"\"\n",
    "    for i in range(num_iterations):\n",
    "        w_prev = w\n",
    "        b_prev = b\n",
    "        # BEGIN CODE HERE\n",
    "        # Cost and gradient calculation\n",
    "        sigma, cost = compute_cost(w, b, X, Y)\n",
    "        dw, db = gradient(w, b, X, Y, sigma)\n",
    "        # update rule\n",
    "        w = w_prev - dw * learning_rate\n",
    "        b = b_prev - db * learning_rate\n",
    "        #END CODE HERE\n",
    "\n",
    "        # Print the cost every 100 training iterations\n",
    "        if i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost)) \n",
    "\n",
    "    return w,b,dw,db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bdnvS5wlrcQT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50b609d638a66ed65c95004ba78d192f",
     "grade": true,
     "grade_id": "cell-3c58cac7b833a102",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "w, b, X, Y = np.array([1.,2.]), 2., np.array([[1.,3.],[2.,4.],[-1.,-3.2]]), np.array([1,0,1])\n",
    "w, b, dw, db = update_parameters(w, b, X, Y, num_iterations= 100, learning_rate = 0.009)\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))\n",
    "print (\"dw = \" + str(dw))\n",
    "print (\"db = \" + str(db))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CxHSKGB9s2I7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39f7a59ae15e7a0a69849981e41cc1c8",
     "grade": false,
     "grade_id": "cell-5972f0bc2ef5bf8c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "Cost after iteration 0: 5.801545\n",
    "w = [0.19033591 0.12259159]\n",
    "b = 1.9253598300845747\n",
    "dw = [0.67752042 1.41625495]\n",
    "db = 0.21919450454067657\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3bnW_pZtuYc2",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dcd98e8e2455a816b1dd8790a5306a59",
     "grade": false,
     "grade_id": "cell-206c6de13177420f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**2.6 Predict** Implement the predict() function by calculating the $y'$ and then convert the probabilities to actual predictions 0 or 1 using 0.5 as threshold (check slides). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "VaAnQYNywYAj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98453d6cf1120f316025f3059887fac0",
     "grade": false,
     "grade_id": "cell-24896766b07ecd4f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    Arguments:\n",
    "    w -- weights\n",
    "    b -- bias, a scalar\n",
    "    X -- input data\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    Y_prediction = np.zeros((m,))\n",
    "    \n",
    "    # BEGIN CODE HERE\n",
    "    # Compute vector \"sigma\" predicting the probabilities of input X\n",
    "    bw = ... #(Optional)\n",
    "    # X =  ... #(Optional)\n",
    "    sigma = sigmoid(np.dot(X, w) + b)\n",
    "    \n",
    "    # Convert probabilities of each instance (of sigma) to actual predictions.\n",
    "    below_threshold_indices = (sigma < 0.5)\n",
    "    sigma[below_threshold_indices] = 0\n",
    "    above_threshold_indices = (sigma > 0.5)\n",
    "    sigma[above_threshold_indices] = 1\n",
    "    Y_prediction = sigma.astype(int)\n",
    "    #END CODE HERE\n",
    "    \n",
    "    assert(Y_prediction.shape == (m,))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "q2P-3OBaxBLT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c05dc02ef30d38e3b6cf8fae342bc4e3",
     "grade": true,
     "grade_id": "cell-dc9eb4e2a0da0d10",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "w = np.array([0.1124579,0.23106775])\n",
    "b = -0.3\n",
    "X = np.array([[1.,1.2],[-1.1,2.],[-3.2,0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fhPhPQZvx4TC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbe3b2c5e724ae28aa31729124ef4a87",
     "grade": false,
     "grade_id": "cell-9ad0176df00b6db8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "predictions = [1 1 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "LSEzK5Cc0E3X",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "270bed39335e5969497ffeecd21c0630",
     "grade": false,
     "grade_id": "cell-4363754ff1f87e60",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**2.7 Exercise** Put all the above blocks in the right order to create a model in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "oy4UD-zR0Sps",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87403c6f9eca3fa5182d3c494fdf48eb",
     "grade": true,
     "grade_id": "cell-c82b256d30be76dd",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of update_parameters()\n",
    "\n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    # BEGIN CODE HERE\n",
    "    # initialize parameters\n",
    "    w, b = initialize(X_train.shape[1])\n",
    "\n",
    "    # Gradient descent\n",
    "    w, b, dw, db = update_parameters(w, b, X_train, Y_train, num_iterations, learning_rate)\n",
    "    \n",
    "    # Predict test/train set examples\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "    #END CODE HERE\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "\n",
    "    d = {\"Y_prediction_test\": Y_prediction_test, \n",
    "        \"Y_prediction_train\" : Y_prediction_train, \n",
    "        \"w\" : w, \n",
    "        \"b\" : b,\n",
    "        \"learning_rate\" : learning_rate,\n",
    "        \"num_iterations\": num_iterations}\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eSv1oc0IgJUd",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd21e5fc5056f1abfbe5e6ad62d1ab60",
     "grade": false,
     "grade_id": "cell-2ed9838dc6fc1c78",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**2.8 Exercise** Create your own dataset from a multivariate normal distribution to test the model with a total of 2000 samples. The mean and covariance matrix are given for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_observations = 1000 #number of observations of each\n",
    "mean_class1 = [0, 0]\n",
    "mean_class2 = [1, 4]\n",
    "cov_matrix =  [[0.5, 0],[0, 0.5]]\n",
    "\n",
    "# BEGIN CODE HERE\n",
    "x1 = np.random.multivariate_normal(mean_class1, cov_matrix, num_observations) # Using the mean for the class 1\n",
    "x2 = np.random.multivariate_normal(mean_class2, cov_matrix, num_observations) # Using the mean for the class 2\n",
    "\n",
    "# TIP: check numpy vstack and hstack\n",
    "X = np.vstack((x1,x2)) #Combine features together\n",
    "y = np.hstack((np.zeros(num_observations),np.ones(num_observations))) #Create the labels (Tip: Assign to Class1 label 1 or 0, and to Class2 the one left)\n",
    "#END CODE HERE\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(X[0:num_observations, 0],\n",
    "            X[0:num_observations, 1],\n",
    "            c = 'r', alpha = .4)\n",
    "plt.scatter(X[num_observations:, 0],\n",
    "            X[num_observations:, 1],\n",
    "            c = 'b', alpha = .4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "w7lyf-hkmMJV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1582fad4c9094837510023d1a66fa421",
     "grade": false,
     "grade_id": "cell-ecbabdb9ea4f45da",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Your plot should look like similar to this:\n",
    "\n",
    "![plot](https://raw.githubusercontent.com/sakrifor/public/master/machine_learning_course/images/plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "N6gklYbei7Te",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0501b0063f279c1dfde4374a8c5abd3",
     "grade": false,
     "grade_id": "cell-911f6638e52cfc11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.9 Exercise** Split your dataset into train and test set and then use the model function to evaluate your model. Be careful to include both classes in train and test set. Finally, make a plot containing the samples and the line the model has learned. Use [train_test_split from sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) to split X and y to train and test sets of 50% and 50%, respectively. You should also use the shuffle parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "0e0BE1vJaEiM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05e708a8bcfa86f52587ab70f8b000ce",
     "grade": true,
     "grade_id": "cell-199f5d6fb1cac508",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, train_size=0.5, random_state=77, shuffle=True)\n",
    "#END CODE HERE\n",
    "\n",
    "d = model(X_train,y_train,X_test,y_test,num_iterations = 1000, learning_rate = 0.001)\n",
    "\n",
    "# Plot again\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(X[0:num_observations, 0], \n",
    "            X[0:num_observations, 1],\n",
    "            c = 'r', alpha = .4)\n",
    "plt.scatter(X[num_observations:, 0], \n",
    "            X[num_observations:, 1],\n",
    "            c = 'b', alpha = .4)\n",
    "\n",
    "x_boundary = np.linspace(-3, 4, 1000) # Return evenly spaced numbers over a specified interval.\n",
    "weights =  d['w'][0]\n",
    "y_boundary = -((weights*x_boundary/d['w'][1]) + (d['b']/d['w'][1]))\n",
    "\n",
    "plt.plot(x_boundary, y_boundary, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6Zk3fQGIR0A"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "Cost after iteration 0: 0.693147\n",
    "Cost after iteration 100: 0.600447\n",
    "Cost after iteration 200: 0.539996\n",
    "Cost after iteration 300: 0.498561\n",
    "Cost after iteration 400: 0.468604\n",
    "Cost after iteration 500: 0.445865\n",
    "Cost after iteration 600: 0.427867\n",
    "Cost after iteration 700: 0.413113\n",
    "Cost after iteration 800: 0.400661\n",
    "Cost after iteration 900: 0.389897\n",
    "train accuracy: 83.6 %\n",
    "test accuracy: 80.3 %\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDlwjY4P2QXD"
   },
   "source": [
    "**2.10 Optional Exercise:** This exercise is optional, but if you implement it you will receive a bonus. Moreover, it will make the following exercise much easier (+ it will help you in the future in general). Let's create a class containing all the neccessary functions to train a Logistic Regression model and make predictions.\n",
    "\n",
    "**self** represents the instance of the class. By using the **self** keyword we can access the attributes (public variables) and methods (functions) of the class in python [Source](https://www.geeksforgeeks.org/self-in-python-class/). It binds the attributes with the given arguments of an instance. Therefore, for the class MyLogisticRegression, we can create an instance of this class:\n",
    "\n",
    "```\n",
    "lr = MyLogisticRegression(...)\n",
    "```\n",
    "And we can use its public variables and methods\n",
    "```\n",
    "lr.num_iterations = 2000\n",
    "print(lr.num_iterations) #Will print the public variable\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHQgqRe5786m"
   },
   "outputs": [],
   "source": [
    "from numpy import exp\n",
    "\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, num_iterations=2000, learning_rate=0.004):\n",
    "      self.w = None\n",
    "      self.b = None\n",
    "      # BEGIN CODE HERE\n",
    "      self.num_iterations = num_iterations\n",
    "      self.learning_rate = learning_rate\n",
    "      #END CODE HERE\n",
    "\n",
    "    def _sigmoid(self, t):\n",
    "        \"\"\"\n",
    "        Compute the sigmoid of t\n",
    "        Arguments:\n",
    "        t -- A numpy array of any size\n",
    "        Return:\n",
    "        s -- sigmoid(t)\n",
    "        \"\"\"\n",
    "        # BEGIN CODE HERE\n",
    "        s = 1 / (1 + np.exp(-1 * t))\n",
    "        #END CODE HERE\n",
    "        return s\n",
    "\n",
    "    def _initialize(self, dim):\n",
    "      \"\"\"\n",
    "      Argument:\n",
    "        dim -- the number of parameters\n",
    "      \"\"\"\n",
    "      # BEGIN CODE HERE\n",
    "      self.w = np.zeros(dim)\n",
    "      self.b = 0\n",
    "      #END CODE HERE\n",
    "\n",
    "      assert(self.w.shape == (dim,))\n",
    "      assert(isinstance(self.b, float) or isinstance(self.b, int))\n",
    "\n",
    "      #Note here that there is no return command, because this function saves w and b in self (public variables of each instance)\n",
    "\n",
    "    def _compute_cost(self, X, Y):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        X -- input data\n",
    "        Y -- target or label vector\n",
    "        Return:\n",
    "        sigma -- the sigmoid of the z\n",
    "        cost -- cost for logistic regression\n",
    "        \"\"\"\n",
    "        # BEGIN CODE HERE\n",
    "        bw = np.insert(self.w, 0, self.b) #(Optional) don't forget that in order to use variables w and b, you should use self.\n",
    "        X = np.c_[np.ones(X.shape[0]),X] #(Optional)\n",
    "        sigma = self._sigmoid(np.dot(X, bw))\n",
    "        cost = (-1 / len(X)) * np.sum(Y * np.log(sigma) + (1 - Y) * np.log(1 - sigma))\n",
    "        #END CODE HERE\n",
    "\n",
    "        return sigma, cost\n",
    "\n",
    "    def _gradient(self, X, Y, sigma):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        X -- input data\n",
    "        Y -- target or label vector\n",
    "        sigma -- the sigmoid of the z\n",
    "        Return:\n",
    "        dw -- gradient of the loss with respect to w (numpy array)\n",
    "        db -- gradient of the loss with respect to b (scalar)\n",
    "        \"\"\"\n",
    "        # BEGIN CODE HERE\n",
    "        bw = np.insert(self.w, 0, self.b) #(Optional) don't forget that in order to use variables w and b, you should use self.\n",
    "        X = np.c_[np.ones(X.shape[0]),X] #(Optional)\n",
    "        grad = (1 / X.shape[0]) * np.dot(X.T, sigma - Y)  #(Optional)\n",
    "        dw = grad[1:]\n",
    "        db = grad[0]\n",
    "        #END CODE HERE\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "    def _update_parameters(self, X, Y):\n",
    "        \"\"\"\n",
    "        This function optimizes w and b by running a gradient descent algorithm\n",
    "\n",
    "          Arguments:\n",
    "          X -- input data\n",
    "          Y -- target or label vector\n",
    "\n",
    "          Returns:\n",
    "          params -- dictionary containing the weights w and bias b\n",
    "          grads -- dictionary containing the gradients of the weights and bias with respect to the cost function.\n",
    "        \"\"\"\n",
    "        for i in range(self.num_iterations):\n",
    "            w_prev = self.w\n",
    "            b_prev = self.b\n",
    "\n",
    "            sigma, cost = self._compute_cost(X, Y)\n",
    "            dw, db = self._gradient(X, Y, sigma)\n",
    "\n",
    "            # BEGIN CODE HERE\n",
    "            self.w = w_prev - dw * self.learning_rate\n",
    "            self.b = b_prev - db * self.learning_rate\n",
    "            #END CODE HERE\n",
    "\n",
    "        return dw,db\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "\n",
    "        Arguments:\n",
    "        X -- input data\n",
    "\n",
    "        Returns:\n",
    "        Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "        '''\n",
    "        m = X.shape[0]\n",
    "        Y_prediction = np.zeros((m,))\n",
    "\n",
    "        # BEGIN CODE HERE\n",
    "        # Compute vector \"sigma\" predicting the probabilities of input X\n",
    "        bw = np.insert(self.w, 0, self.b) #(Optional) don't forget that in order to use variables w and b, you should use self.\n",
    "        X = np.c_[np.ones(X.shape[0]),X] #(Optional)\n",
    "        sigma = self._sigmoid(np.dot(X, bw))\n",
    "\n",
    "        # Convert probabilities of each instance (of sigma) to actual predictions.\n",
    "        below_threshold_indices = (sigma < 0.5)\n",
    "        sigma[below_threshold_indices] = 0\n",
    "        above_threshold_indices = (sigma > 0.5)\n",
    "        sigma[above_threshold_indices] = 1\n",
    "        Y_prediction = sigma.astype(int)\n",
    "        #END CODE HERE\n",
    "        assert(Y_prediction.shape == (m,))\n",
    "\n",
    "        return Y_prediction\n",
    "\n",
    "    def fit_evaluate(self, X_train, Y_train, X_test, Y_test):\n",
    "        \"\"\"\n",
    "        Builds the logistic regression model by calling the function you've implemented previously\n",
    "\n",
    "        Arguments:\n",
    "        X_train -- training set represented by a numpy array\n",
    "        Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "        X_test -- test set represented by a numpy array of shape\n",
    "        Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "        num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "        learning_rate -- hyperparameter representing the learning rate used in the update rule of update_parameters()\n",
    "\n",
    "        Returns:\n",
    "        d -- dictionary containing information about the model.\n",
    "        \"\"\"\n",
    "        # BEGIN CODE HERE\n",
    "        # initialize parameters\n",
    "        self._initialize(X_train.shape[1])\n",
    "        # Gradient descent\n",
    "        dw, db = self._update_parameters(X_train, Y_train)\n",
    "\n",
    "        # Predict test/train set examples\n",
    "        Y_prediction_test = self.predict(X_test)\n",
    "        Y_prediction_train = self.predict(X_train)\n",
    "        #END CODE HERE\n",
    "\n",
    "        # Print train/test Errors\n",
    "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "\n",
    "        d = {\"Y_prediction_test\": Y_prediction_test,\n",
    "            \"Y_prediction_train\" : Y_prediction_train,\n",
    "            \"w\" : w,\n",
    "            \"b\" : b,\n",
    "            \"learning_rate\" : self.learning_rate,\n",
    "            \"num_iterations\": self.num_iterations}\n",
    "\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linearModel = MyLogisticRegression(1000, 0.001)\n",
    "d = linearModel.fit_evaluate(X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y0Wzirm_yht"
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "train accuracy: 83.6 %\n",
    "test accuracy: 80.3 %\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cL4U8X6rodey",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fe28e603be5cc8992b63c695915b305",
     "grade": false,
     "grade_id": "cell-f379407e8f4b0d61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.0 Regularization ##\n",
    "\n",
    "Rewrite any of the above functions in the below block so as the Logistic Regression to have the option to run with **L1** and **L2** regularization. Rewrite only the functions needed. (Tip: If you use the class, this excercise is much easier. You should rewrite the class, changing the constructor of the class and only one more function to implement the regularization. Then, you will be able to call those commands for the different regularization parameters)\n",
    "\n",
    "```\n",
    "linearModel = MyLogisticRegression(1000, 0.001, 'l1')\n",
    "linearModel = MyLogisticRegression(1000, 0.001, 'l2')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "deletable": false,
    "id": "oemHripT8nvE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59b6aba4f70a65a633cc67da4a35c1d0",
     "grade": true,
     "grade_id": "cell-00c4b14e03d90376",
     "locked": false,
     "points": 25,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN CODE HERE\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, num_iterations=2000, learning_rate=0.004, regularization = 'l1'):\n",
    "      self.w = None\n",
    "      self.b = None\n",
    "      # BEGIN CODE HERE\n",
    "      self.num_iterations = num_iterations\n",
    "      self.learning_rate = learning_rate\n",
    "      self.regularization = regularization\n",
    "      #END CODE HERE\n",
    "\n",
    "    def _sigmoid(self, t):\n",
    "        \"\"\"\n",
    "        Compute the sigmoid of t\n",
    "        Arguments:\n",
    "        t -- A numpy array of any size\n",
    "        Return:\n",
    "        s -- sigmoid(t)\n",
    "        \"\"\"\n",
    "        # BEGIN CODE HERE\n",
    "        s = 1 / (1 + np.exp(-1 * t))\n",
    "        #END CODE HERE\n",
    "        return s\n",
    "\n",
    "    def _initialize(self, dim):\n",
    "      \"\"\"\n",
    "      Argument:\n",
    "        dim -- the number of parameters\n",
    "      \"\"\"\n",
    "      # BEGIN CODE HERE\n",
    "      self.w = np.zeros(dim)\n",
    "      self.b = 0\n",
    "      #END CODE HERE\n",
    "\n",
    "      assert(self.w.shape == (dim,))\n",
    "      assert(isinstance(self.b, float) or isinstance(self.b, int))\n",
    "\n",
    "      #Note here that there is no return command, because this function saves w and b in self (public variables of each instance)\n",
    "\n",
    "    def _compute_cost(self, X, Y):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        X -- input data\n",
    "        Y -- target or label vector\n",
    "        Return:\n",
    "        sigma -- the sigmoid of the z\n",
    "        cost -- cost for logistic regression\n",
    "        \"\"\"\n",
    "        # BEGIN CODE HERE\n",
    "        bw = np.insert(self.w, 0, self.b) #(Optional) don't forget that in order to use variables w and b, you should use self.\n",
    "        X = np.c_[np.ones(X.shape[0]),X] #(Optional)\n",
    "        L = 5000\n",
    "        if self.regularization == 'l1':\n",
    "            R = np.sum(np.power(bw,2))\n",
    "            a = L / (2*X.shape[0])\n",
    "        elif self.regularization == 'l2' :\n",
    "            R = np.sum(np.absolute(bw))\n",
    "            a = L / X.shape[0]\n",
    "        sigma = self._sigmoid(np.dot(X, bw))\n",
    "        cost = (-1 / len(X)) * np.sum(Y * np.log(sigma) + (1 - Y) * np.log(1 - sigma)) + a * R\n",
    "        #END CODE HERE\n",
    "\n",
    "        return sigma, cost\n",
    "\n",
    "    def _gradient(self, X, Y, sigma):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        X -- input data\n",
    "        Y -- target or label vector\n",
    "        sigma -- the sigmoid of the z\n",
    "        Return:\n",
    "        dw -- gradient of the loss with respect to w (numpy array)\n",
    "        db -- gradient of the loss with respect to b (scalar)\n",
    "        \"\"\"\n",
    "        # BEGIN CODE HERE\n",
    "        bw = np.insert(self.w, 0, self.b) #(Optional) don't forget that in order to use variables w and b, you should use self.\n",
    "        X = np.c_[np.ones(X.shape[0]),X] #(Optional)\n",
    "        grad = (1 / X.shape[0]) * np.dot(X.T, sigma - Y)  #(Optional)\n",
    "        dw = grad[1:]\n",
    "        db = grad[0]\n",
    "        #END CODE HERE\n",
    "\n",
    "        return dw, db\n",
    "\n",
    "    def _update_parameters(self, X, Y):\n",
    "        \"\"\"\n",
    "        This function optimizes w and b by running a gradient descent algorithm\n",
    "\n",
    "          Arguments:\n",
    "          X -- input data\n",
    "          Y -- target or label vector\n",
    "\n",
    "          Returns:\n",
    "          params -- dictionary containing the weights w and bias b\n",
    "          grads -- dictionary containing the gradients of the weights and bias with respect to the cost function.\n",
    "        \"\"\"\n",
    "        for i in range(self.num_iterations):\n",
    "            w_prev = self.w\n",
    "            b_prev = self.b\n",
    "\n",
    "            sigma, cost = self._compute_cost(X, Y)\n",
    "            dw, db = self._gradient(X, Y, sigma)\n",
    "\n",
    "            # BEGIN CODE HERE\n",
    "            self.w = w_prev - dw * self.learning_rate\n",
    "            self.b = b_prev - db * self.learning_rate\n",
    "            #END CODE HERE\n",
    "\n",
    "        return dw,db\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "\n",
    "        Arguments:\n",
    "        X -- input data\n",
    "\n",
    "        Returns:\n",
    "        Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "        '''\n",
    "        m = X.shape[0]\n",
    "        Y_prediction = np.zeros((m,))\n",
    "\n",
    "        # BEGIN CODE HERE\n",
    "        # Compute vector \"sigma\" predicting the probabilities of input X\n",
    "        bw = np.insert(self.w, 0, self.b) #(Optional) don't forget that in order to use variables w and b, you should use self.\n",
    "        X = np.c_[np.ones(X.shape[0]),X] #(Optional)\n",
    "        sigma = self._sigmoid(np.dot(X, bw))\n",
    "\n",
    "        # Convert probabilities of each instance (of sigma) to actual predictions.\n",
    "        below_threshold_indices = (sigma < 0.5)\n",
    "        sigma[below_threshold_indices] = 0\n",
    "        above_threshold_indices = (sigma > 0.5)\n",
    "        sigma[above_threshold_indices] = 1\n",
    "        Y_prediction = sigma.astype(int)\n",
    "        #END CODE HERE\n",
    "        assert(Y_prediction.shape == (m,))\n",
    "\n",
    "        return Y_prediction\n",
    "\n",
    "    def fit_evaluate(self, X_train, Y_train, X_test, Y_test):\n",
    "        \"\"\"\n",
    "        Builds the logistic regression model by calling the function you've implemented previously\n",
    "\n",
    "        Arguments:\n",
    "        X_train -- training set represented by a numpy array\n",
    "        Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "        X_test -- test set represented by a numpy array of shape\n",
    "        Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "        num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "        learning_rate -- hyperparameter representing the learning rate used in the update rule of update_parameters()\n",
    "\n",
    "        Returns:\n",
    "        d -- dictionary containing information about the model.\n",
    "        \"\"\"\n",
    "        # BEGIN CODE HERE\n",
    "        # initialize parameters\n",
    "        self._initialize(X_train.shape[1])\n",
    "        # Gradient descent\n",
    "        dw, db = self._update_parameters(X_train, Y_train)\n",
    "\n",
    "        # Predict test/train set examples\n",
    "        Y_prediction_test = self.predict(X_test)\n",
    "        Y_prediction_train = self.predict(X_train)\n",
    "        #END CODE HERE\n",
    "\n",
    "        # Print train/test Errors\n",
    "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "\n",
    "        d = {\"Y_prediction_test\": Y_prediction_test,\n",
    "            \"Y_prediction_train\" : Y_prediction_train,\n",
    "            \"w\" : self.w,\n",
    "            \"b\" : self.b,\n",
    "            \"learning_rate\" : self.learning_rate,\n",
    "            \"num_iterations\": self.num_iterations}\n",
    "\n",
    "        return d\n",
    "\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "4SyI-VtVvefd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 80.3 %\n",
      "test accuracy: 81.0 %\n",
      "train accuracy: 80.3 %\n",
      "test accuracy: 81.0 %\n"
     ]
    }
   ],
   "source": [
    "#You can freely test your code here\n",
    "# BEGIN CODE HERE\n",
    "\n",
    "linearModel = MyLogisticRegression(1000, 0.001, 'l1')\n",
    "d = linearModel.fit_evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "linearModel = MyLogisticRegression(1000, 0.001, 'l2')\n",
    "d = linearModel.fit_evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5UsPoeQ8VpmV",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9786e9d2abc991be3dc7dd11946c0c9",
     "grade": false,
     "grade_id": "cell-7b1bcd8fb3c836ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Questions** ##\n",
    "\n",
    "Answer below!\n",
    "\n",
    "1. Your model should achieve around 80% accuracy in the test set. If you want to improve the accuracy what changes you should make? Report the changes and the results. (It can reach above 95%)\n",
    "2. Besides using a specific number of iterations for your model what else you can do to stop the training? \n",
    "3. Do you notice any differences when using the L1 or L2 regularization? Is so, why? If not, why? (Answer based on what you've learned in class)\n",
    "\n",
    "Bonus Question:\n",
    "*What parts of this assignment were not clear or misleading? Are there any other comments on this assignment?* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Answers** ##\n",
    "\n",
    "1. Increasing the number of iterations or the learning rate by an order of magnitude yields significantly better results\n",
    "(example in the block below)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "deletable": false,
    "id": "TNz5dOTw8hWz",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb6ea3a1a4efda46c432400ce6058e66",
     "grade": true,
     "grade_id": "cell-daef52bcbcbb8de9",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 97.2 %\n",
      "test accuracy: 97.3 %\n",
      "train accuracy: 97.2 %\n",
      "test accuracy: 97.3 %\n"
     ]
    }
   ],
   "source": [
    "linearModel = MyLogisticRegression(10000, 0.001) #Increasing the number of iterations tenfold\n",
    "d = linearModel.fit_evaluate(X_train, y_train, X_test, y_test)\n",
    "\n",
    "linearModel = MyLogisticRegression(1000, 0.010) #Increasing the learning rate tenfold\n",
    "d = linearModel.fit_evaluate(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Keeping a record of the previous values of the cost variable, and checking whether it's getting smaller with each iteration. If we reach a point where the cost increases, we should stop the training as we are moving away from the desired result. This method is also known as *Early Stopping*\n",
    "3. There is no difference to the result using L1 or L2 regularization. This result is expected since regularization decreases weights matching the polynomial terms of a higher degree. However, since our model is a simple line of the form `y = ax + b` there are no weights that belong to a high degree term. Thus, there is no effect to the current model."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "9717_Antonios_Keremidis_keremidis@ece.auth.gr_LinearModels.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}